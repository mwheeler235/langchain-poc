{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccbbaf70-5e04-4e1c-9bd2-4b33061f249c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.1.8)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-openai) (0.2.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-openai) (1.30.5)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.65 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (0.1.67)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (2.7.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (8.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.12.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain-openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.65->langchain-core<0.3,>=0.2.2->langchain-openai) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (2.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (1.26.16)\n",
      "Requirement already satisfied: PyPDF2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai; pip install PyPDF2; pip install python-dotenv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a1436c2-2f9b-4f85-a622-1c51fb2376e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from PyPDF2 import PdfReader\n",
    "import dotenv\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "#os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a26d97a-e834-4ebe-8259-29bc91fd58c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1196bc12-035f-43b2-9c03-c9d90bc18e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader('resumes/Matt Wheeler Resume 2024.pdf')\n",
    "with open('resumes/txt/mw_resume_2024.txt', 'w') as f:\n",
    "    f.write(reader.pages[0].extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68779e84-22b0-4133-b347-4dc6cd424358",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad3ea4b-e50a-4901-8a6e-21efab4555b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"candidate_name\": \"Matt Wheeler\",\n",
      "    \"candidate_interests\": \"problem definition and data-driven storytelling\",\n",
      "    \"what_are_the_biggest_topics_in_this_resume\": \"Machine learning models, distributed computing, building visualizations, cloud applications, customer campaign value optimization, Quasi-Experimental Evaluation Design (QED), Multi-Touch Attribution customer insights, neural networks (SBERT) for NLP Topic Modeling, customer duplicate matching pipeline\",\n",
      "    \"candidate_programming_languages\": \"Python, Spark, SQL, SAS\",\n",
      "    \"python_libraries_used\": \"Tensorflow, PyTorch, scikit-learn, Prophet, DeepAR, Catboost, NLTK, Spacy\",\n",
      "    \"does_candidate_have_ml_experience\": \"Yes\",\n",
      "    \"does_candidate_have_llm_experience\": \"Yes\",\n",
      "    \"does_candidate_have_web_design_experience\": \"No\",\n",
      "    \"does_candidate_have_data_visualization_experience\": \"Yes\",\n",
      "    \"candidate_industries_with_experience\": \"Marketing/CRM\",\n",
      "    \"is_candidate_good_fit_for_position\": \"Yes\",\n",
      "    \"is_candidate_a_cat\": \"No\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('resumes/txt/mw_resume_2024.txt') as f:\n",
    "    resume = f.read()\n",
    "\n",
    "# Create prompt\n",
    "q = f'''\n",
    "You are a hiring manager reviewing a candidate resume for a marketing senior data scientist position.\n",
    "\n",
    "\n",
    "Extract specified values from the source text.\n",
    "Return answer as JSON object with following fields:\n",
    "- \"candidate_name\" <string>\n",
    "- \"candidate_interests\" <string>\n",
    "- \"what_are_the_biggest_topics_in_this_resume\" <string>\n",
    "- \"candidate_programming_languages\" <string>\n",
    "- \"python_libraries_used\" <string>\n",
    "- \"does_candidate_have_ml_experience\" <string>\n",
    "- \"does_candidate_have_llm_experience\" <string>\n",
    "- \"does_candidate_have_web_design_experience\" <string>\n",
    "- \"does_candidate_have_data_visualization_experience\" <string>\n",
    "- \"candidate_industries_with_experience\" <string>\n",
    "- \"is_candidate_good_fit_for_position\" <string>\n",
    "- \"is_candidate_a_cat\" <string>\n",
    "\n",
    "\n",
    "Do not infer any data based on previous training, strictly use only source text given below as input.\n",
    "========\n",
    "{resume}\n",
    "========\n",
    "'''\n",
    "\n",
    "# OpenAI call, print result\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": q,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "llm_response = chat_completion.choices[0].message.content\n",
    "print(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e2eace-c52a-4d46-8b82-809d325c2ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's write song lyrics together. The song will use the chords A,C,D, and G\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the first line:\n",
      " In 2024, language models surely control music...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language models have already made significant advancements in the music industry, with AI-powered platforms like Jukedeck and Amper Music generating original music based on user input and preferences. In 2024, it is likely that language models will have an even greater influence on music creation, potentially leading to AI-generated hit songs and personalized music experiences tailored to individual listeners.\n",
      "\n",
      "These language models can analyze lyrics, melodies, and musical styles to create unique compositions that resonate with audiences. They can also assist musicians and producers in the creative process, offering suggestions and feedback to enhance their music.\n",
      "\n",
      "Additionally, language models can help music streaming services better understand user preferences and provide personalized recommendations, leading to a more tailored listening experience for each individual.\n",
      "\n",
      "Overall, in 2024, language models will likely play a significant role in shaping the future of music, revolutionizing the way music is created, consumed, and shared.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the next line:\n",
      " can you write a song about this content?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Verse 1)\n",
      "In a world where language models reign,\n",
      "They shape our music and control our brain,\n",
      "Creating melodies so sweet and clear,\n",
      "Guided by algorithms, no need for fear.\n",
      "\n",
      "(Chorus)\n",
      "Language models control the beat,\n",
      "Crafting songs that are oh so sweet,\n",
      "They know just what we want to hear,\n",
      "In 2024, the music is clear.\n",
      "\n",
      "(Verse 2)\n",
      "No more human composers in sight,\n",
      "Just AI creating music with all its might,\n",
      "Every note, every chord, perfectly arranged,\n",
      "In the language models, we're all deranged.\n",
      "\n",
      "(Chorus)\n",
      "Language models control the beat,\n",
      "Crafting songs that are oh so sweet,\n",
      "They know just what we want to hear,\n",
      "In 2024, the music is clear.\n",
      "\n",
      "(Bridge)\n",
      "But as we dance to these digital tunes,\n",
      "Do we lose our connection to the moon?\n",
      "Or can we still find beauty in the machine,\n",
      "Where the lines blur between real and dream.\n",
      "\n",
      "(Chorus)\n",
      "Language models control the beat,\n",
      "Crafting songs that are oh so sweet,\n",
      "They know just what we want to hear,\n",
      "In 2024, the music is clear.\n",
      "\n",
      "(Outro)\n",
      "So let us embrace this new age of sound,\n",
      "Where language models reign, and creativity is bound,\n",
      "For in their algorithmic grace,\n",
      "We may find a new kind of musical embrace.\n"
     ]
    }
   ],
   "source": [
    "def generate_response(prompt):\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "    llm_response = chat_completion.choices[0].message.content\n",
    "    \n",
    "    return llm_response\n",
    "    \n",
    "print(\"Let's write song lyrics together. The song will use the chords A,C,D, and G\") \n",
    "prompt = input(\"Enter the first line:\\n\")\n",
    "verse = generate_response(prompt)\n",
    "print(verse)\n",
    "\n",
    "while True:\n",
    "  line = input(\"\\nEnter the next line:\\n\")    \n",
    "  prompt += \"\\n\" + line\n",
    "  verse = generate_response(prompt)\n",
    "  print(verse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab4118-4010-4893-bc82-3fcb890ad3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
